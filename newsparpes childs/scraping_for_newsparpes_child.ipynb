{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping DCG.media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCRAPING\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "### DATABASES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "### VISUALISATION\n",
    "import plotly.express as px\n",
    "\n",
    "### DIVERS\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "### FORMAT\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'le-managemental'\n",
    "abbr = 'lmg'\n",
    "tld = '.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number = 1\n",
    "top_url = f'https://www.{website+tld}'\n",
    "top_search_url = f'{top_url}/page/{page_number}/?s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenir le nombre de pages de résultats de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_page_results(top_search_url):\n",
    "    r = rq.get(top_search_url)\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    page_numbers = soup.find_all(\"a\", class_=\"page-numbers\")\n",
    "    pages = [int(page.text) for page in page_numbers if page.text.isdigit()]\n",
    "    if pages:\n",
    "        return max(pages)  # Le numéro le plus élevé correspond au total de pages\n",
    "    return 1\n",
    "get_max_page_results(top_search_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenir la liste des pages de résultats de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.le-managemental.fr/page/1/?s']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_results_pages(page_final):\n",
    "    urls = []\n",
    "    for i in range(page_final):\n",
    "        i = f'{top_url}/page/{i+1}/?s'\n",
    "        urls.append(i)\n",
    "    return urls\n",
    "get_all_results_pages(get_max_page_results(top_search_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenir tous les liens des articles sur une page de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_on_page(search_results):\n",
    "    urls_articles = []\n",
    "    s = rq.Session()\n",
    "    for p in tqdm(search_results):\n",
    "        r = s.get(p)\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        articles = soup.find_all('h2', class_ = 'entry-title')\n",
    "        for article in articles:\n",
    "            url = article.find('a', href=True)['href']\n",
    "            urls_articles.append(url)\n",
    "    return urls_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b412ff550ad4eaca7455d98f9c38855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['https://www.le-managemental.fr/gestion-du-poste-client-pourquoi-former-ses-collaborateurs/',\n",
       " 'https://www.le-managemental.fr/comment-optimiser-vos-chances-de-trouver-un-emploi-dans-le-secteur-entrepreneurial/',\n",
       " 'https://www.le-managemental.fr/comment-faire-une-bonne-analyse-de-lexistant/',\n",
       " 'https://www.le-managemental.fr/comment-faire-une-analyse-critique-dun-sujet/',\n",
       " 'https://www.le-managemental.fr/code-barre-png-generer-un-code-barre-gratuitement/',\n",
       " 'https://www.le-managemental.fr/parcelsapp-connexion-pour-le-suivi-de-son-colis/',\n",
       " 'https://www.le-managemental.fr/ma-vie-rh-la-poste-decouvrez-les-services-rh-essentiels/',\n",
       " 'https://www.le-managemental.fr/agendis-62-votre-assistant-de-planification-en-ligne/',\n",
       " 'https://www.le-managemental.fr/webcsat-58-outil-pour-levaluation-de-la-satisfaction-client/',\n",
       " 'https://www.le-managemental.fr/guide-didentification-au-webmail-urban-group-ratp-connexion-astuces-et-conseils/',\n",
       " 'https://www.le-managemental.fr/optimisez-la-performance-de-votre-entreprise-grace-a-compapro/',\n",
       " 'https://www.le-managemental.fr/logo-nutella-histoire-et-signification/',\n",
       " 'https://www.le-managemental.fr/zimbra-cd66-revolutionnez-vos-communications-en-entreprise/',\n",
       " 'https://www.le-managemental.fr/a-quel-gafam-linkedin-est-il-rattache-demystification/',\n",
       " 'https://www.le-managemental.fr/intraligne-air-france-connexion-et-fonctionnalites-pour-le-personnel/',\n",
       " 'https://www.le-managemental.fr/libelle-de-la-voie-cle-de-voute-de-ladresse-postale/',\n",
       " 'https://www.le-managemental.fr/automatisation-et-securite-proteger-vos-locaux-efficacement/',\n",
       " 'https://www.le-managemental.fr/medisysnet-tout-savoir-sur-cette-solution-en-ligne/',\n",
       " 'https://www.le-managemental.fr/redaction-des-clauses-dun-jeu-concours-en-boutique-conseils-pour-une-conformite-juridique/',\n",
       " 'https://www.le-managemental.fr/ipn-air-france-tout-ce-quil-faut-savoir-pour-les-employes/',\n",
       " 'https://www.le-managemental.fr/swedishop-tout-savoir-sur-sa-politique-de-livraison-et-retours/',\n",
       " 'https://www.le-managemental.fr/comment-le-coaching-peut-il-transformer-un-manager/',\n",
       " 'https://www.le-managemental.fr/les-metiers-en-demande-dans-le-secteur-social-zoom-sur-le-role-du-moniteur-educateur/',\n",
       " 'https://www.le-managemental.fr/mieux-recruter-comment-les-entreprises-peuvent-beneficier-des-plateformes-demploi-locales/',\n",
       " 'https://www.le-managemental.fr/selectionner-le-bon-prestataire-technique-pour-vos-evenements-dentreprise-un-enjeu-majeur/',\n",
       " 'https://www.le-managemental.fr/comment-optimiser-ses-revenus-en-etant-independant/',\n",
       " 'https://www.le-managemental.fr/comment-mettre-en-place-un-plan-de-recrutement/',\n",
       " 'https://www.le-managemental.fr/quelle-est-lutilite-des-techniques-marketing/',\n",
       " 'https://www.le-managemental.fr/comment-calculer-les-charges-dune-sarl/',\n",
       " 'https://www.le-managemental.fr/quel-metier-avec-un-bts-design-despace/',\n",
       " 'https://www.le-managemental.fr/quel-est-le-salaire-dun-ingenieur-automobile/',\n",
       " 'https://www.le-managemental.fr/comment-dejaunir-du-plastique-blanc/',\n",
       " 'https://www.le-managemental.fr/redressement-ou-liquidation-quelle-difference/',\n",
       " 'https://www.le-managemental.fr/optimiser-la-relation-fournisseurs-les-6-etapes-cles/',\n",
       " 'https://www.le-managemental.fr/micro-ba-benefice-agricole-explication-du-fonctionnement-de-ce-regime/',\n",
       " 'https://www.le-managemental.fr/protection-de-donnees-mais-qui-est-concerne-par-le-rgpd/',\n",
       " 'https://www.le-managemental.fr/comprendre-la-matrice-raci/',\n",
       " 'https://www.le-managemental.fr/comment-fonctionne-la-chaine-logistique-et-comment-bien-lutiliser/',\n",
       " 'https://www.le-managemental.fr/modele-contrat-de-travail-cdi/',\n",
       " 'https://www.le-managemental.fr/quel-metier-pour-les-hypersensibles/',\n",
       " 'https://www.le-managemental.fr/comprendre-le-siret-dechiffrer-sa-signification-et-son-importance-pour-les-entreprises/',\n",
       " 'https://www.le-managemental.fr/les-etapes-indispensables-pour-se-connecter-a-son-compte-cgos/',\n",
       " 'https://www.le-managemental.fr/pourquoi-opter-pour-b2p-web-pour-vos-echanges-de-fret/',\n",
       " 'https://www.le-managemental.fr/analyse-approfondie-de-la-valeur-du-point-convention-66-pour-les-travailleurs-sociaux/',\n",
       " 'https://www.le-managemental.fr/calendrier-des-paiements-de-leducation-nationale-anticiper-ses-finances/',\n",
       " 'https://www.le-managemental.fr/vetements-de-travail-utilite-symboles-et-tendance/',\n",
       " 'https://www.le-managemental.fr/le-calendrier-de-paie-des-enseignants-dates-cles-et-conseils-avises/',\n",
       " 'https://www.le-managemental.fr/recrutement-international-comment-faciliter-lembauche-de-talents-etrangers-en-france/',\n",
       " 'https://www.le-managemental.fr/poids-palette-europe-guide-exhaustif-pour-les-professionnels-de-la-logistique/',\n",
       " 'https://www.le-managemental.fr/comment-la-formation-continue-peut-transformer-votre-carriere-en-logistique/',\n",
       " 'https://www.le-managemental.fr/comment-bien-choisir-son-agenda-semainier/',\n",
       " 'https://www.le-managemental.fr/comment-rediger-une-demande-dexplication-efficace/',\n",
       " 'https://www.le-managemental.fr/comment-faire-une-analyse-critique-dun-sujet/',\n",
       " 'https://www.le-managemental.fr/comment-coacher-un-surdoue/',\n",
       " 'https://www.le-managemental.fr/comment-debuter-dans-lentrepreneuriat/',\n",
       " 'https://www.le-managemental.fr/comment-faire-la-comptabilite-dentreprise/',\n",
       " 'https://www.le-managemental.fr/comment-faire-un-plan-de-marketing/']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_articles_on_page(get_all_results_pages(get_max_page_results(top_search_url)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérer les infos qu'on souhaite sur chaque article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info(r, url_article):\n",
    "    # Liste de variables\n",
    "    noms_variables = [\n",
    "        'url',  # URL scrapée\n",
    "        'canonical_url', 'slug', 'meta_title', 'meta_desc',  # Infos issues de la balise meta\n",
    "        'date_published', 'date_modified',  # Infos dates\n",
    "        'author',  # Parfois en meta\n",
    "        'title', 'category', 'views', 'reading_time',  # Metadonnées contenues ailleurs que dans la balise meta\n",
    "        'content', 'raw_content'  # Contenu de la page\n",
    "    ]\n",
    "    \n",
    "    # Initialisation du dictionnaire\n",
    "    data = {nom: np.nan for nom in noms_variables}\n",
    "    \n",
    "    data['url'] = url_article\n",
    "    \n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "    \n",
    "    try:\n",
    "        data['canonical_url'] = soup.find('link', {'rel': 'canonical'})['href']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        data['slug'] = data['canonical_url'].split('/')[-2] if data['canonical_url'] else np.nan\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data['meta_title'] = soup.find('meta', {'property': 'og:title'})['content']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data['meta_desc'] = soup.find('meta', {'property': 'og:description'})['content']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data['date_published'] = pd.to_datetime(soup.find('meta', {'property': 'article:published_time'})['content'][:-6], utc=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data['date_modified'] = pd.to_datetime(soup.find('meta', {'property': 'article:modified_time'})['content'][:-6], utc=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data['author'] = soup.find(\"meta\", {'name': 'author'})['content']\n",
    "    except:\n",
    "        try:\n",
    "            data['author'] = soup.find(class_=\"author\").text.split('Publié par ')[-1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        data['title'] = soup.find('h1').text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data['category'] = [x.text for x in soup.find_all(class_=\"tdb-entry-category\")]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data['views'] = int(soup.find('span', class_=lambda x: x and x.startswith('td-nr-views-')).text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data['reading_time'] = int(soup.find('meta', {'name': 'twitter:data2'})['content'].split(' ')[0]) if soup.find('meta', {'name': 'twitter:data2'}) and 'minutes' in soup.find('meta', {'name': 'twitter:data2'})['content'] else np.nan\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data['content'] = BeautifulSoup(str(soup.find(\"div\", class_=\"td-post-content\")), 'lxml').get_text()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        data['raw_content'] = str(soup.find(\"div\", class_=\"td-post-content\"))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Ajout de features\n",
    "    data['length'] = len(str(data['content']).split())\n",
    "    \n",
    "    if pd.notnull(data['date_published']):\n",
    "        data['days_since_published'] = int((pd.Timestamp.now(tz='UTC') - data['date_published']).days)\n",
    "    else:\n",
    "        data['days_since_published'] = np.nan\n",
    "    \n",
    "    # Création de la série\n",
    "    series = pd.Series(data)\n",
    "    series.name = url_article\n",
    "    \n",
    "    # Ajout de features supplémentaires\n",
    "    if pd.notnull(data.get('views')) and pd.notnull(data.get('days_since_published')):\n",
    "        series['views_daily'] = series['views'] / series['days_since_published']\n",
    "        series['views_monthly'] = series['views_daily'] * 30\n",
    "    else:\n",
    "        series['views_daily'] = np.nan\n",
    "        series['views_monthly'] = np.nan\n",
    "    \n",
    "    series['website'] = top_url\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e3617b53c3407d9d64060d6e5898e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "article_list = get_articles_on_page(get_all_results_pages(get_max_page_results(top_search_url)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ce6514a15948978bacac3fb00019b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch 1 / 1:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping terminé. Total d'articles : 57\n",
      "3.3462815284729004\n"
     ]
    }
   ],
   "source": [
    "# Import des packages\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# Initialisation du compteur\n",
    "start_time = time.time()\n",
    "\n",
    "# Fonction principale qui sauvegarde le DataFrame dans un fichier CSV et le retourne\n",
    "def scrape_all_articles(urls, batch_size=250, max_workers=20):\n",
    "    # Initialisation d'une session réutilisable\n",
    "    session = rq.Session()\n",
    "\n",
    "    # Création d'une fonction qui traite chaque URL\n",
    "    def process_url(url):\n",
    "            try:\n",
    "                r = session.get(url)\n",
    "                return get_article_info(r, url)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur pour {url}: {str(e)}\")\n",
    "                return pd.Series(name=url)\n",
    "\n",
    "    # Utilise ThreadPoolExecutor pour paralléliser le traitement\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Parcourt la liste d'URLs par lots de taille 'batch_size'\n",
    "        for i in range(0, len(urls), batch_size):\n",
    "            # Extrait un lot d'URLs\n",
    "            batch = urls[i:i+batch_size]\n",
    "            # Crée et soumet des tâches pour chaque URL du lot\n",
    "            futures = [executor.submit(process_url, url) for url in batch]\n",
    "            \n",
    "            # Traite les résultats au fur et à mesure qu'ils sont terminés\n",
    "            for future in tqdm(as_completed(futures), total=len(batch), desc=f\"Batch {i//batch_size + 1} / {len(urls)//batch_size+1}\"):\n",
    "                # Récupère le résultat de la tâche\n",
    "                result = future.result()\n",
    "                # Si le résultat n'est pas None (pas d'erreur), l'ajoute aux résultats\n",
    "                if result is not None:\n",
    "                    results.append(result)\n",
    "    \n",
    "    # Création du DataFrame final\n",
    "    df_final = pd.DataFrame(results)\n",
    "    \n",
    "    # Ajout de colonnes calculées\n",
    "    df_final['website'] = top_url\n",
    "    df_final['scraping_date'] = pd.Timestamp.now(tz='UTC')\n",
    "\n",
    "    df_final.columns = ['article_url', 'article_canonical_url', 'article_slug',\n",
    "       'article_meta_title', 'article_meta_desc', 'article_date_published',\n",
    "       'article_date_modified', 'article_author', 'article_title',\n",
    "       'article_category', 'article_views', 'article_reading_time',\n",
    "       'article_content', 'article_raw_content', 'article_length',\n",
    "       'days_since_published', 'article_views_daily', 'article_views_monthly',\n",
    "       'website', 'scraping_date']\n",
    "\n",
    "    # Sauvegarde en CSV\n",
    "    df_final.to_csv(f'scraping_{abbr}.csv', sep='|', index=True)\n",
    "    print(f\"Scraping terminé. Total d'articles : {len(df_final)}\")\n",
    "    return df_final\n",
    "\n",
    "df = scrape_all_articles(article_list)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138a1da2ea4c4ebd88b8c28bb9c423e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzol\\anaconda3\\Lib\\site-packages\\ydata_profiling\\model\\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'cannot reindex on an axis with duplicate labels')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb6db14d6c54a7daedc4060b6ec828e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa508206b8a401586531e2b2dc1c469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523c8b27e43a4bbdac2db3caa04a855e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Création d'un rapport de profil avec pandas_profiling\n",
    "profile = ProfileReport(df, title=f\"{abbr.title()} Scraping Report\", explorative=True)\n",
    "\n",
    "# Génération du rapport au format HTML\n",
    "profile.to_file(f\"scraping_report_{abbr}.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
